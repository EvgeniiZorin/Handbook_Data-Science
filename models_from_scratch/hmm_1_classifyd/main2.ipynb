{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3aabc7",
   "metadata": {},
   "source": [
    "# Import and init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f5e79",
   "metadata": {},
   "source": [
    "Binary classification:\n",
    "- `0`: Edgar Allan Poe\n",
    "- `1`: Robert Frost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386469ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCEPTABLE_CHARS = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "ACCEPTABLE_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT_CHARS = string.punctuation\n",
    "PUNCT_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_END_CHARS = '!.?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94feb703",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebc255",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143377c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# wget https://raw.githubusercontent.com/csawtelle/udemy-machine-learning-examples/refs/heads/master/hmm_class/edgar_allan_poe.txt\n",
    "# wget https://raw.githubusercontent.com/csawtelle/udemy-machine-learning-examples/refs/heads/master/hmm_class/robert_frost.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b0bb0",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0f5ec",
   "metadata": {},
   "source": [
    "### Edgar Allan Poe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edgar_allan_poe.txt', 'r') as f:\n",
    "    c1_0 = f.readlines()\n",
    "\n",
    "c1_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_txt(txt: list[str]\n",
    "                ) -> str:\n",
    "    # Strip leading and trailing newlines\n",
    "    txt_proc = [i.strip().lower() for i in txt]\n",
    "    # remove nonsencical lines\n",
    "    txt_proc = [\n",
    "        i for i in txt_proc \n",
    "        if len(\n",
    "            set(i).difference(set(ACCEPTABLE_CHARS))\n",
    "        ) == 0\n",
    "    ]\n",
    "    # Join with whitespace\n",
    "    txt_proc = ' '.join(txt_proc)\n",
    "    # Remove some illegal characters\n",
    "    for i in ('\"', '(', ')'):\n",
    "        txt_proc = txt_proc.replace(i, '')\n",
    "    # Add whitespace padding to sentence-end characters and other punctuation\n",
    "    for i in (SENTENCE_END_CHARS + ','):\n",
    "        txt_proc = txt_proc.replace(i, f\" {i} \")\n",
    "    # Replace 2 or more whitespaces with only one\n",
    "    txt_proc = re.sub(r'\\s+', ' ', txt_proc)\n",
    "    return txt_proc\n",
    "\n",
    "c1_1 = process_txt(c1_0)\n",
    "c1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split into sentences and count\n",
    "c1_1_sentences = [i.strip() for i in c1_1.split('.')]\n",
    "print(len(c1_1_sentences))\n",
    "print(c1_1_sentences[:3])\n",
    "\n",
    "c1_1_train, c1_1_test = train_test_split(\n",
    "    c1_1_sentences,\n",
    "    test_size = 0.15,\n",
    "    random_state = 32\n",
    ")\n",
    "print(len(c1_1_train), len(c1_1_test))\n",
    "\n",
    "c1_1_train = ' . '.join(c1_1_train)\n",
    "c1_1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a611bac",
   "metadata": {},
   "source": [
    "### Robert Frost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('robert_frost.txt', 'r') as f:\n",
    "    c2_0 = f.readlines()\n",
    "\n",
    "c2_0[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acff164",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_1 = process_txt(c2_0)\n",
    "c2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa347ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split into sentences and count\n",
    "c2_1_sentences = [i.strip() for i in c2_1.split('.')]\n",
    "print(len(c2_1_sentences))\n",
    "print(c2_1_sentences[:3])\n",
    "\n",
    "c2_1_train, c2_1_test = train_test_split(\n",
    "    c2_1_sentences,\n",
    "    test_size = 0.05,\n",
    "    random_state = 32\n",
    ")\n",
    "print(len(c2_1_train), len(c2_1_test))\n",
    "\n",
    "c2_1_train = ' . '.join(c2_1_train)\n",
    "c2_1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62c94e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a54d9d7e",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad341d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = c1_1_test + c2_1_test\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [0 for _ in range(len(c1_1_test))] + [1 for _ in range(len(c2_1_test))]\n",
    "print(len(y_test))\n",
    "y_test[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4841a",
   "metadata": {},
   "source": [
    "## Combined vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83969ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = c1_1_train + ' ' + c2_1_train\n",
    "vocab = list(set(vocab.split(' ')))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f43f6e",
   "metadata": {},
   "source": [
    "# MM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505e2cd",
   "metadata": {},
   "source": [
    "## Create ISD (Pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tokens(txt: str\n",
    "                      ) -> dict:\n",
    "    return set(txt.split(' '))\n",
    "\n",
    "get_unique_tokens(c1_1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02467cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dict_ISD(txt: str\n",
    "                    ) -> dict:\n",
    "    # Get set of all unique tokens\n",
    "    # unique_tokens = get_unique_tokens(txt)\n",
    "    unique_tokens = vocab\n",
    "    # initialise Add-One Smoothing dictionary \n",
    "    dict_start = {i: 1 for i in unique_tokens}\n",
    "    # Get a list of initial words\n",
    "    initial_words0 = re.findall(\n",
    "        r'[.!] ?([a-zA-Z0-9\\-]+)',\n",
    "        txt\n",
    "    )\n",
    "    initial_words = [i for i in initial_words0 if i != '-']\n",
    "    # Count each one\n",
    "    for i in set(initial_words):\n",
    "        if i not in dict_start:\n",
    "            dict_start[i] = initial_words.count(i)\n",
    "        else:\n",
    "            dict_start[i] += initial_words.count(i)\n",
    "    # Normalise and log-probability\n",
    "    for i in dict_start:\n",
    "        dict_start[i] /= len(initial_words0) + len(set(initial_words))\n",
    "    for i in dict_start:\n",
    "        dict_start[i] = math.log(dict_start[i], 10)\n",
    "    # Sort the dictionary based on value\n",
    "    dict_start = dict(sorted(dict_start.items(), key = lambda item: item[1], reverse = True))\n",
    "    # Add out-of-vocabulary (OOV) token\n",
    "    dict_start['OOV'] = min(dict_start.values())\n",
    "    return dict_start\n",
    "\n",
    "c1_isd = return_dict_ISD(c1_1_train)\n",
    "c1_isd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_isd['OOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e84d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_isd = return_dict_ISD(c2_1_train)\n",
    "c2_isd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_isd['OOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56629d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (c1_isd, c2_isd):\n",
    "    assert 'OOV' in i, \"ERROR: OOV token not present.\"\n",
    "    assert min(i.values()) < 0, \"ERROR\"\n",
    "    assert max(i.values()) < 0, \"ERROR\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716435dc",
   "metadata": {},
   "source": [
    "## Create STT (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda26938",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.index('writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeeadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_1_train.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ac9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int(100)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_STT(txt: str\n",
    "                    ) -> dict:\n",
    "    dict_stt = {i: {j: 1 for j in vocab} for i in vocab}\n",
    "    train_corpus = txt.split(' ')\n",
    "    for index in range(len(train_corpus) - 1):\n",
    "        from_word = train_corpus[index]\n",
    "        to_word   = train_corpus[index+1]\n",
    "        dict_stt[from_word][to_word] += 1\n",
    "    # count dict\n",
    "    dict_counts = {i: train_corpus.count(i) + len(set(train_corpus)) for i in vocab}\n",
    "    # Divide by counts\n",
    "    min_value = int(100)\n",
    "    for i in dict_counts:\n",
    "        subdict = dict_stt[i]\n",
    "        subdict = {j: math.log(subdict[j] / dict_counts[i], 10) for j in subdict}\n",
    "        dict_stt[i] = subdict\n",
    "        # Get smallest value for OOV\n",
    "        min_value = min(\n",
    "            min_value,\n",
    "            min(subdict.values())\n",
    "        )\n",
    "    # Add OOV\n",
    "    dict_stt['OOV'] = min_value\n",
    "    return dict_stt\n",
    "\n",
    "c1_stt = create_dict_STT(c1_1_train)\n",
    "c1_stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec27fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_stt['writer']['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_stt = create_dict_STT(c2_1_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2_stt['writer']['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e642190",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_1_train.split(' ').count('writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b96a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2adfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (c1_stt, c2_stt):\n",
    "    assert 'OOV' in i, \"ERROR: OOV not present.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b4efe",
   "metadata": {},
   "source": [
    "# Classify sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746246a",
   "metadata": {},
   "source": [
    "## Classify one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f525c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 32\n",
    "c = 5 if a == 1 else 50\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748fd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    'a': {\n",
    "        'a': 5,\n",
    "        'b': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "True if 'c' in a and 'b' in a['c'] else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence: str,\n",
    "                  verbose: bool = True\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Returns boolean prediction:\n",
    "    - `0`: Edgar Allan Poe\n",
    "    - `1`: Robert Frost\n",
    "    \"\"\"\n",
    "    snt_proc = process_txt([sentence]).split(' ')\n",
    "\n",
    "    probabilities = list()\n",
    "\n",
    "    # Calculate probability of class 0\n",
    "    proba_c0 = 0\n",
    "    # first word\n",
    "    first_word = snt_proc[0] if snt_proc[0] in c1_isd else 'OOV'\n",
    "    proba_c0 += c1_isd[first_word]\n",
    "    # all subsequent words\n",
    "    for i in range(1, len(snt_proc) - 1):\n",
    "        word, next_word = snt_proc[i], snt_proc[i+1]\n",
    "        try:\n",
    "            proba = c1_stt[word][next_word]\n",
    "        except KeyError as e:\n",
    "            print(f\"{word} or {next_word} not present in vocab.\")\n",
    "            proba = c1_stt['OOV']\n",
    "        proba_c0 += proba\n",
    "    probabilities.append(proba_c0)\n",
    "\n",
    "    # Calculate probability of class 1\n",
    "    proba_c1 = 0\n",
    "    # first word\n",
    "    first_word = snt_proc[0] if snt_proc[0] in c2_isd else 'OOV'\n",
    "    proba_c1 += c2_isd[first_word]\n",
    "    for i in range(1, len(snt_proc) - 1):\n",
    "        word, next_word = snt_proc[i], snt_proc[i+1]\n",
    "        try:\n",
    "            proba = c2_stt[word][next_word]\n",
    "        except KeyError as e:\n",
    "            print(f\"{word} or {next_word} not present in vocab.\")\n",
    "            proba = c2_stt['OOV']\n",
    "        proba_c1 += proba\n",
    "    probabilities.append(proba_c1)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Log probabilities of each class:\")\n",
    "        print(f\" - `0`: {proba_c0}\")\n",
    "        print(f\" - `1`: {proba_c1}\")\n",
    "    return int(np.argmax(probabilities))\n",
    "\n",
    "\n",
    "snt1 = 'Not long ago, the writer of these lines, In the mad pride of intellectuality oceane.'\n",
    "predict_class(snt1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65109068",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in x_test:\n",
    "    predictions.append(predict_class(i))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "accuracy_score(\n",
    "    y_test,\n",
    "    predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9ac883",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(\n",
    "    y_test,\n",
    "    predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadcfc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(\n",
    "    y_test,\n",
    "    predictions\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-ml-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
