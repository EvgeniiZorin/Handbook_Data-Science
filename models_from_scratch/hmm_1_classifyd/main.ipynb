{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3aabc7",
   "metadata": {},
   "source": [
    "# Import and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386469ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCEPTABLE_CHARS = string.ascii_letters + string.digits + string.punctuation + ' '\n",
    "ACCEPTABLE_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT_CHARS = string.punctuation\n",
    "PUNCT_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_END_CHARS = '!.?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94feb703",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ebc255",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143377c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# wget https://raw.githubusercontent.com/csawtelle/udemy-machine-learning-examples/refs/heads/master/hmm_class/edgar_allan_poe.txt\n",
    "# wget https://raw.githubusercontent.com/csawtelle/udemy-machine-learning-examples/refs/heads/master/hmm_class/robert_frost.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b0bb0",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0f5ec",
   "metadata": {},
   "source": [
    "### Edgar Allan Poe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edgar_allan_poe.txt', 'r') as f:\n",
    "    c1_0 = f.readlines()\n",
    "\n",
    "c1_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_txt(txt: list[str]\n",
    "                ) -> str:\n",
    "    # Strip leading and trailing newlines\n",
    "    txt_proc = [i.strip().lower() for i in txt]\n",
    "    # remove nonsencical lines\n",
    "    txt_proc = [\n",
    "        i for i in txt_proc \n",
    "        if len(\n",
    "            set(i).difference(set(ACCEPTABLE_CHARS))\n",
    "        ) == 0\n",
    "    ]\n",
    "    # Join with whitespace\n",
    "    txt_proc = ' '.join(txt_proc)\n",
    "    # Remove some illegal characters\n",
    "    for i in ('\"', '(', ')'):\n",
    "        txt_proc = txt_proc.replace(i, '')\n",
    "    # Add whitespace padding to sentence-end characters and other punctuation\n",
    "    for i in (SENTENCE_END_CHARS + ','):\n",
    "        txt_proc = txt_proc.replace(i, f\" {i} \")\n",
    "    # Replace 2 or more whitespaces with only one\n",
    "    txt_proc = re.sub(r'\\s+', ' ', txt_proc)\n",
    "    return txt_proc\n",
    "\n",
    "c1_1 = process_txt(c1_0)\n",
    "c1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc134fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a611bac",
   "metadata": {},
   "source": [
    "### Robert Frost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('robert_frost.txt', 'r') as f:\n",
    "    c2_0 = f.readlines()\n",
    "\n",
    "c2_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acff164",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_1 = process_txt(c2_0)\n",
    "c2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83969ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = c1_1 + ' ' + c2_1\n",
    "vocab = list(set(vocab.split(' ')))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f43f6e",
   "metadata": {},
   "source": [
    "# MM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505e2cd",
   "metadata": {},
   "source": [
    "## Create ISD (Pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tokens(txt: str\n",
    "                      ) -> dict:\n",
    "    return set(txt.split(' '))\n",
    "\n",
    "get_unique_tokens(c1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02467cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dict_ISD(txt: str\n",
    "                    ) -> dict:\n",
    "    # Get set of all unique tokens\n",
    "    # unique_tokens = get_unique_tokens(txt)\n",
    "    unique_tokens = vocab\n",
    "    # initialise Add-One Smoothing dictionary \n",
    "    dict_start = {i: 1 for i in unique_tokens}\n",
    "    # Get a list of initial words\n",
    "    initial_words0 = re.findall(\n",
    "        r'[.!] ?([a-zA-Z0-9\\-]+)',\n",
    "        txt\n",
    "    )\n",
    "    initial_words = [i for i in initial_words0 if i != '-']\n",
    "    # Count each one\n",
    "    for i in set(initial_words):\n",
    "        if i not in dict_start:\n",
    "            dict_start[i] = initial_words.count(i)\n",
    "        else:\n",
    "            dict_start[i] += initial_words.count(i)\n",
    "    # Normalise and log-probability\n",
    "    for i in dict_start:\n",
    "        dict_start[i] /= len(initial_words0) + len(set(initial_words))\n",
    "    for i in dict_start:\n",
    "        dict_start[i] = math.log(dict_start[i], 10)\n",
    "    # Sort the dictionary based on value\n",
    "    dict_start = dict(sorted(dict_start.items(), key = lambda item: item[1], reverse = True))\n",
    "    return dict_start\n",
    "\n",
    "c1_isd = return_dict_ISD(c1_1)\n",
    "c1_isd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1f5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_isd['writer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e84d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_isd = return_dict_ISD(c2_1)\n",
    "c2_isd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56629d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (c1_isd, c2_isd):\n",
    "    print(min(i.values()), max(i.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716435dc",
   "metadata": {},
   "source": [
    "## Create STT (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda26938",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.index('writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeeadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_1.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_STT(txt: str\n",
    "                    ) -> dict:\n",
    "    dict_stt = {i: {j: 1 for j in vocab} for i in vocab}\n",
    "    train_corpus = txt.split(' ')\n",
    "    for index in range(len(train_corpus) - 1):\n",
    "        from_word = train_corpus[index]\n",
    "        to_word   = train_corpus[index+1]\n",
    "        dict_stt[from_word][to_word] += 1\n",
    "    # count dict\n",
    "    dict_counts = {i: train_corpus.count(i) + len(set(train_corpus)) for i in vocab}\n",
    "    # Divide by counts\n",
    "    for i in dict_counts:\n",
    "        subdict = dict_stt[i]\n",
    "        subdict = {j: math.log(subdict[j] / dict_counts[i], 10) for j in subdict}\n",
    "        dict_stt[i] = subdict\n",
    "    return dict_stt\n",
    "\n",
    "c1_stt = create_dict_STT(c1_1)\n",
    "c1_stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec27fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_stt['writer']['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_stt = create_dict_STT(c2_1)\n",
    "for i in ['throve', 'sake', 'of']:\n",
    "    print(c2_stt['writer'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_stt['writer']['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e642190",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_1.split(' ').count('writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b96a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_stt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b4efe",
   "metadata": {},
   "source": [
    "# Classify sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2911a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "snt1 = ['Not long ago, the writer of these lines, In the mad pride of intellectuality.']\n",
    "\n",
    "snt1_proc = process_txt(snt1).split(' ')\n",
    "snt1_proc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_c1 = 0\n",
    "\n",
    "proba_c1 += c1_isd[snt1_proc[0]]\n",
    "for i in range(1, len(snt1_proc) - 1):\n",
    "    word, next_word = snt1_proc[i], snt1_proc[i+1]\n",
    "    proba = c1_stt[word][next_word]\n",
    "    proba_c1 += proba\n",
    "    print(proba, word, next_word)\n",
    "proba_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda97daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_c2 = 0\n",
    "\n",
    "proba_c2 += c2_isd[snt1_proc[0]]\n",
    "for i in range(1, len(snt1_proc) - 1):\n",
    "    word, next_word = snt1_proc[i], snt1_proc[i+1]\n",
    "    proba = c2_stt[word][next_word]\n",
    "    proba_c2 += proba\n",
    "    print(proba, word, next_word)\n",
    "proba_c2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handbook-data-science-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
